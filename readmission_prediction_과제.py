# -*- coding: utf-8 -*-
"""Readmission_Prediction_과제.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yYb1kRpQ5WS72q9uY2gPqdwOfuhgldEq
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
df=pd.read_csv("/content/drive/MyDrive/기계학습/과제/diabetic_data.csv")

df

len(df['readmitted'])

df['readmitted']=df['readmitted'].replace(['NO','>30','<30'],['0','0','1'])
df['readmitted']=df['readmitted'].astype('int')

#dropping encounter_id,patient_nbr as it is just identifier
#weight as it contains 97% null values
#examide, citogliption as they have only one categorical value
#diag_1,diag_2,diag_3 as we are considering number_of_diagnosis
df=df.drop(['encounter_id','patient_nbr','weight','examide','citoglipton','diag_1','diag_2','diag_3'],axis=1)

df.replace('?',np.nan,inplace=True)

df.isnull().sum()

#discharge_disposition_id informs where the patient has gone after discharging. Ids 11,13,14,19,20,21 represent death or Hospice they cannot be returned
df=df.loc[~df.discharge_disposition_id.isin([11,13,14,19,20,21])]

#Numerical Columns in dataset
df_num_cols=df[['time_in_hospital','num_lab_procedures','num_procedures','num_medications','number_outpatient','number_emergency','number_inpatient','number_diagnoses']]
df_num_cols.isnull().sum()

df_num_cols=pd.concat([df_num_cols],axis=1)

df_num_cols.columns

df_num_cols.corr()

#Categorical Columns in dataset
categorical_columns=['race', 'gender','payer_code','max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide',
       'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',
       'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',
       'miglitol', 'troglitazone', 'tolazamide', 'insulin',
       'glyburide-metformin', 'glipizide-metformin',
       'glimepiride-pioglitazone', 'metformin-rosiglitazone',
       'metformin-pioglitazone', 'change', 'diabetesMed']

df['race']=df['race'].fillna('UKN')
df['medical_specialty']=df['medical_specialty'].fillna('UKN')
df['payer_code']=df['payer_code'].fillna('UKN')

df

df1=df.groupby('medical_specialty').size().sort_values(ascending=False)

df1.head(10)

top_10=['UKN','InternalMedicine','Emergency/Trauma','Family/GeneralPractice','Cardiology','Surgery-General','Nephrology','Orthopedics','Orthopedics-Reconstructive','Radiologist']

df.loc[~df.medical_specialty.isin(top_10),'medical_specialty']= 'Other'

df.describe()

df['admission_type_id']=df['admission_type_id'].astype('str')
df['discharge_disposition_id']=df['discharge_disposition_id'].astype('str')
df['admission_source_id']=df['admission_source_id'].astype('str')

df['admission_type_id'].unique()

df.to_csv('df_naive.csv')

df_cat=pd.get_dummies(df[categorical_columns+ ['admission_type_id','discharge_disposition_id','admission_source_id','medical_specialty']],drop_first=True)

list(df_cat)

df_cat

df_num_cols

df['age']

dff=pd.concat([df_cat,df_num_cols,df['age']],axis=1)

len(dff)

dff

dff.dtypes

age_id = {'[0-10)':5,
          '[10-20)':15,
          '[20-30)':25,
          '[30-40)':35,
          '[40-50)':45,
          '[50-60)':55,
          '[60-70)':65,
          '[70-80)':75,
          '[80-90)':85,
          '[90-100)':95}
dff['age_group'] = dff.age.replace(age_id)

dff.columns

dff=pd.concat([dff,df['readmitted']],axis=1)

dff.columns

dff.dtypes

dff=dff.drop(['age'],axis=1)

dff.dtypes

df=dff

df.corr()

df = df.sample(n = len(df))
df = df.reset_index(drop = True)

df_valid_test=df.sample(frac=0.30)

df_test = df_valid_test.sample(frac = 0.5)
df_valid = df_valid_test.drop(df_test.index)
df_train=df.drop(df_valid_test.index)

def calc_prevalence(y_actual):
    return (sum(y_actual)/len(y_actual))

print('Test prevalence(n = %d):%.3f'%(len(df_test),calc_prevalence(df_test.readmitted.values)))
print('Valid prevalence(n = %d):%.3f'%(len(df_valid),calc_prevalence(df_valid.readmitted.values)))
print('Train all prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.readmitted.values)))

rows_pos = df_train.readmitted == 1
df_train_pos = df_train.loc[rows_pos]
df_train_neg = df_train.loc[~rows_pos]

# merge the balanced data
df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos))],axis = 0)

# shuffle the order of training samples
df_train = df_train.sample(n = len(df_train)).reset_index(drop = True)

df_train

X_train = df_train.loc[:, df_train.columns != 'readmitted']
y_train=df_train['readmitted']
X_valid =  df_valid.loc[:, df_valid.columns != 'readmitted']
y_valid=df_valid['readmitted']

X_test =  df_test.loc[:, df_test.columns != 'readmitted']
y_test=df_test['readmitted']

from sklearn.preprocessing import StandardScaler

scaler  = StandardScaler()
scaler.fit(X_train)

df_train.describe()

X_train_tf = scaler.transform(X_train)
X_valid_tf = scaler.transform(X_valid)

X_test_tf = scaler.transform(X_test)

y_test

pd.DataFrame(X_train_tf)[9].unique()

X_train.shape

X_train_tf.shape

from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
def calc_specificity(y_actual, y_pred, thresh):
    # calculates specificity
    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)

def print_report(y_actual, y_pred, thresh):

    auc = roc_auc_score(y_actual, y_pred)
    accuracy = accuracy_score(y_actual, (y_pred > thresh))
    recall = recall_score(y_actual, (y_pred > thresh))
    precision = precision_score(y_actual, (y_pred > thresh))
    specificity = calc_specificity(y_actual, y_pred, thresh)
    print('AUC:%.3f'%auc)
    print('accuracy:%.3f'%accuracy)
    print('recall:%.3f'%recall)
    print('precision:%.3f'%precision)
    print('specificity:%.3f'%specificity)
    print('prevalence:%.3f'%calc_prevalence(y_actual))
    print(' ')
    return auc, accuracy, recall, precision, specificity

thresh = 0.5